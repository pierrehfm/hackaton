{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du fichier de pollution...\n",
      "\n",
      "=== Nettoyage de base ===\n",
      "\n",
      "=== Nettoyage des chaînes de caractères ===\n",
      "\n",
      "=== Renommage des colonnes ===\n",
      "\n",
      "=== Informations sur le dataset nettoyé ===\n",
      "Nombre de lignes : 630\n",
      "Nombre de colonnes : 15\n",
      "\n",
      "Colonnes :\n",
      "['id', 'gid', 'code_zone', 'zone', 'date', 'date_dif', 'code_pol', 'polluant', 'etat', 'niveau', 'com_court', 'commentaire', 'OBJECTID', 'SHAPE__Area', 'SHAPE__Length']\n",
      "\n",
      "Aperçu des données :\n",
      "   id  gid  code_zone             zone                      date  \\\n",
      "0   1    1       2016  Zone Alpine Ain 2024-01-14 00:00:00+00:00   \n",
      "1   2    2       2016  Zone Alpine Ain 2024-01-13 00:00:00+00:00   \n",
      "2   3    3       2016  Zone Alpine Ain 2024-01-14 00:00:00+00:00   \n",
      "3   4    4       2016  Zone Alpine Ain 2024-01-13 00:00:00+00:00   \n",
      "4   5    5       2016  Zone Alpine Ain 2024-01-14 00:00:00+00:00   \n",
      "\n",
      "                 date_dif  code_pol         polluant                etat  \\\n",
      "0  2024/01/13 00:00:00+00         8  Dioxyde d'azote  PAS DE DEPASSEMENT   \n",
      "1  2024/01/13 00:00:00+00         8  Dioxyde d'azote  PAS DE DEPASSEMENT   \n",
      "2  2024/01/13 00:00:00+00         7            Ozone  PAS DE DEPASSEMENT   \n",
      "3  2024/01/13 00:00:00+00         7            Ozone  PAS DE DEPASSEMENT   \n",
      "4  2024/01/13 00:00:00+00         5  Particules PM10  PAS DE DEPASSEMENT   \n",
      "\n",
      "    niveau com_court commentaire  OBJECTID   SHAPE__Area  SHAPE__Length  \n",
      "0  #19FF19     aucun       aucun         1  3.359408e+09  346225.361125  \n",
      "1  #19FF19     aucun       aucun         2  3.359408e+09  346225.361125  \n",
      "2  #19FF19     aucun       aucun         3  3.359408e+09  346225.361125  \n",
      "3  #19FF19     aucun       aucun         4  3.359408e+09  346225.361125  \n",
      "4  #19FF19     aucun       aucun         5  3.359408e+09  346225.361125  \n",
      "\n",
      "Fichier nettoyé sauvegardé sous : data/output/episodes_de_pollution_nettoyes.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier\n",
    "print(\"Chargement du fichier de pollution...\")\n",
    "df_pollution = pd.read_csv(\"data/episodes_de_pollution_prevus_ou_constates.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "# Nettoyage de base\n",
    "print(\"\\n=== Nettoyage de base ===\")\n",
    "df_pollution.columns = df_pollution.columns.str.strip()  # Nettoyer noms de colonnes\n",
    "df_pollution = df_pollution.drop_duplicates()  # Retirer les doublons\n",
    "df_pollution['date_prevision'] = pd.to_datetime(df_pollution['date_prevision'], errors='coerce')  # Convertir dates\n",
    "df_pollution = df_pollution.dropna(subset=[\"date_prevision\", \"lib_zone\", \"lib_pol\"])  # Supprimer les lignes incomplètes\n",
    "\n",
    "# Nettoyer les chaînes de caractères\n",
    "print(\"\\n=== Nettoyage des chaînes de caractères ===\")\n",
    "for col in ['lib_zone', 'lib_pol', 'etat', 'com_court', 'com_long']:\n",
    "    if col in df_pollution.columns:\n",
    "        df_pollution[col] = df_pollution[col].astype(str).str.strip()\n",
    "\n",
    "# Renommage clair\n",
    "print(\"\\n=== Renommage des colonnes ===\")\n",
    "df_pollution = df_pollution.rename(columns={\n",
    "    \"lib_zone\": \"zone\",\n",
    "    \"date_prevision\": \"date\",\n",
    "    \"lib_pol\": \"polluant\",\n",
    "    \"etat\": \"etat\",\n",
    "    \"couleur\": \"niveau\",\n",
    "    \"com_long\": \"commentaire\"\n",
    "})\n",
    "\n",
    "# Affichage des informations\n",
    "print(\"\\n=== Informations sur le dataset nettoyé ===\")\n",
    "print(f\"Nombre de lignes : {len(df_pollution)}\")\n",
    "print(f\"Nombre de colonnes : {len(df_pollution.columns)}\")\n",
    "print(\"\\nColonnes :\")\n",
    "print(df_pollution.columns.tolist())\n",
    "print(\"\\nAperçu des données :\")\n",
    "print(df_pollution.head())\n",
    "\n",
    "# Sauvegarde du fichier nettoyé\n",
    "output_file = \"data/output/episodes_de_pollution_nettoyes.csv\"\n",
    "df_pollution.to_csv(output_file, index=False, encoding='utf-8')\n",
    "print(f\"\\nFichier nettoyé sauvegardé sous : {output_file}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  code_insee_commune   axe     x_deb      y_deb      x_fin      y_fin  \\\n",
      "0        237676517.0   A28  569981.6  6938140.0  568217.60  6935783.5   \n",
      "2        733131555.0  A620  572626.2  6284049.5  572552.90  6283075.0   \n",
      "4        237676517.0   A28  569985.7  6938129.5  568226.06  6935779.0   \n",
      "6        723333075.0  A630  414987.7  6427724.5  414042.70  6427039.0   \n",
      "9        723333075.0  A630  414969.9  6427708.0  414051.80  6427035.0   \n",
      "\n",
      "   longueur code_traficolor  \n",
      "0      3035            RO76  \n",
      "2       834            TO31  \n",
      "4      3042            RO76  \n",
      "6      1030            BX33  \n",
      "9      1000            BX33  \n"
     ]
    }
   ],
   "source": [
    "df_refdir = pd.read_csv(\"data/refDir.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "# Nettoyage\n",
    "df_refdir.columns = df_refdir.columns.str.strip()\n",
    "df_refdir = df_refdir.drop_duplicates()\n",
    "\n",
    "# Gérer types de données\n",
    "df_refdir[\"code_insee_commune\"] = df_refdir[\"code_insee_commune\"].astype(str)\n",
    "df_refdir = df_refdir.dropna(subset=[\"x_deb\", \"y_deb\", \"x_fin\", \"y_fin\", \"axe\"])\n",
    "\n",
    "# Filtrer les lignes avec longueurs nulles ou négatives\n",
    "df_refdir = df_refdir[df_refdir[\"longueur\"] > 0]\n",
    "\n",
    "# Colonnes utiles seulement\n",
    "colonnes_utiles = [\n",
    "    \"code_insee_commune\", \"axe\", \"x_deb\", \"y_deb\", \"x_fin\", \"y_fin\", \"longueur\", \"code_traficolor\"\n",
    "]\n",
    "df_refdir = df_refdir[colonnes_utiles]\n",
    "\n",
    "print(df_refdir.head())\n",
    "\n",
    "# Sauvegarde du fichier nettoyé\n",
    "output_file = \"data/output/infra_route_refdir.csv\"\n",
    "df_refdir.to_csv(output_file, index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture du fichier DBF en cours...\n",
      "Conversion en CSV en cours...\n",
      "Conversion terminée ! Le fichier a été sauvegardé sous : data/pvo_patrimoine_voirie_pvocomptagecriter.csv\n",
      "Nombre de lignes converties : 2776\n",
      "\n",
      "Aperçu des colonnes :\n",
      "['positionne', 'distanceli', 'nom', 'typecapteu', 'typepostem', 'nbvoies', 'moyennejou', 'debithorai', 'horairedeb', 'identifian', 'identifia0', 'anneerefer', 'estvalide', 'gid']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "import os\n",
    "\n",
    "# Chemin du fichier DBF\n",
    "dbf_file = 'data/pvo_patrimoine_voirie_pvocomptagecriter.dbf'\n",
    "# Chemin du fichier CSV de sortie\n",
    "csv_file = 'data/pvo_patrimoine_voirie_pvocomptagecriter.csv'\n",
    "\n",
    "# Lire le fichier DBF\n",
    "print(\"Lecture du fichier DBF en cours...\")\n",
    "table = DBF(dbf_file, encoding='latin1')\n",
    "\n",
    "# Convertir en DataFrame pandas\n",
    "df = pd.DataFrame(iter(table))\n",
    "\n",
    "# Sauvegarder en CSV\n",
    "print(\"Conversion en CSV en cours...\")\n",
    "df.to_csv(csv_file, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Conversion terminée ! Le fichier a été sauvegardé sous : {csv_file}\")\n",
    "print(f\"Nombre de lignes converties : {len(df)}\")\n",
    "print(\"\\nAperçu des colonnes :\")\n",
    "print(df.columns.tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture du fichier CSV...\n",
      "\n",
      "=== Informations générales sur le dataset ===\n",
      "Nombre total de lignes : 2776\n",
      "Nombre total de colonnes : 14\n",
      "\n",
      "Types de données par colonne :\n",
      "positionne     object\n",
      "distanceli      int64\n",
      "nom            object\n",
      "typecapteu     object\n",
      "typepostem     object\n",
      "nbvoies         int64\n",
      "moyennejou    float64\n",
      "debithorai    float64\n",
      "horairedeb     object\n",
      "identifian      int64\n",
      "identifia0      int64\n",
      "anneerefer    float64\n",
      "estvalide     float64\n",
      "gid             int64\n",
      "dtype: object\n",
      "\n",
      "=== Analyse des valeurs manquantes ===\n",
      "            Valeurs manquantes  Pourcentage\n",
      "moyennejou                 139     5.007205\n",
      "debithorai                 139     5.007205\n",
      "horairedeb                 139     5.007205\n",
      "anneerefer                 139     5.007205\n",
      "estvalide                 2776   100.000000\n",
      "\n",
      "=== Statistiques descriptives des variables numériques ===\n",
      "        distanceli      nbvoies     moyennejou    debithorai   anneerefer\n",
      "count  2776.000000  2776.000000    2637.000000   2637.000000  2637.000000\n",
      "mean     89.569524     1.636527   13691.774365   1251.195677  2022.838074\n",
      "std     165.868604     0.761756   15991.983171   1460.282670     0.589442\n",
      "min       0.000000     1.000000      10.000000      0.000000  2019.000000\n",
      "25%       0.000000     1.000000    3914.000000    411.000000  2023.000000\n",
      "50%      79.000000     1.000000    7118.000000    678.000000  2023.000000\n",
      "75%     102.000000     2.000000   15230.000000   1412.000000  2023.000000\n",
      "max     999.000000     4.000000  103574.000000  17036.000000  2023.000000\n",
      "\n",
      "=== Analyse des valeurs uniques pour les variables catégorielles ===\n",
      "\n",
      "Valeurs uniques dans typecapteu:\n",
      "typecapteu\n",
      "Capteur inductif Criter    2776\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valeurs uniques dans typepostem:\n",
      "typepostem\n",
      "Comptage tous véhicules    2566\n",
      "Comptage vélo               210\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valeurs uniques dans horairedeb:\n",
      "horairedeb\n",
      "08h00    719\n",
      "17h00    634\n",
      "18h00    384\n",
      "07h00    354\n",
      "16h00    195\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Nettoyage des données ===\n",
      "\n",
      "=== Création des visualisations ===\n",
      "\n",
      "Dataset nettoyé sauvegardé sous : data/output/pvo_patrimoine_voirie_pvocomptagecriter_nettoye.csv\n",
      "\n",
      "Visualisations sauvegardées sous :\n",
      "- data/distributions_numeriques.png\n",
      "- data/boxplots_numeriques.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration de l'affichage pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 150)\n",
    "\n",
    "# Lecture du fichier CSV\n",
    "print(\"Lecture du fichier CSV...\")\n",
    "df = pd.read_csv('data/pvo_patrimoine_voirie_pvocomptagecriter.csv')\n",
    "\n",
    "# Affichage des informations générales\n",
    "print(\"\\n=== Informations générales sur le dataset ===\")\n",
    "print(f\"Nombre total de lignes : {len(df)}\")\n",
    "print(f\"Nombre total de colonnes : {len(df.columns)}\")\n",
    "print(\"\\nTypes de données par colonne :\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Analyse des valeurs manquantes\n",
    "print(\"\\n=== Analyse des valeurs manquantes ===\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "missing_info = pd.DataFrame({\n",
    "    'Valeurs manquantes': missing_values,\n",
    "    'Pourcentage': missing_percentage\n",
    "})\n",
    "print(missing_info[missing_info['Valeurs manquantes'] > 0])\n",
    "\n",
    "# Statistiques descriptives pour les colonnes numériques\n",
    "numeric_columns = ['distanceli', 'nbvoies', 'moyennejou', 'debithorai', 'anneerefer']\n",
    "print(\"\\n=== Statistiques descriptives des variables numériques ===\")\n",
    "print(df[numeric_columns].describe())\n",
    "\n",
    "# Analyse des valeurs uniques pour les colonnes catégorielles\n",
    "categorical_columns = ['typecapteu', 'typepostem', 'horairedeb']\n",
    "print(\"\\n=== Analyse des valeurs uniques pour les variables catégorielles ===\")\n",
    "for col in categorical_columns:\n",
    "    print(f\"\\nValeurs uniques dans {col}:\")\n",
    "    print(df[col].value_counts().head())\n",
    "\n",
    "# Nettoyage des données\n",
    "print(\"\\n=== Nettoyage des données ===\")\n",
    "\n",
    "# Conversion et nettoyage des colonnes numériques\n",
    "for col in numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Nettoyage des colonnes catégorielles\n",
    "for col in categorical_columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Création de visualisations\n",
    "print(\"\\n=== Création des visualisations ===\")\n",
    "\n",
    "# 1. Distribution des variables numériques\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i, col in enumerate(numeric_columns, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(data=df, x=col, bins=30)\n",
    "    plt.title(f'Distribution de {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/output/distributions_numeriques.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Boîtes à moustaches pour les variables numériques\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df[numeric_columns])\n",
    "plt.title('Distribution des variables numériques (boîtes à moustaches)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/output/boxplots_numeriques.png')\n",
    "plt.close()\n",
    "\n",
    "# Sauvegarde du dataset nettoyé\n",
    "df.to_csv('data/output/pvo_patrimoine_voirie_pvocomptagecriter_nettoye.csv', index=False)\n",
    "print(\"\\nDataset nettoyé sauvegardé sous : data/output/pvo_patrimoine_voirie_pvocomptagecriter_nettoye.csv\")\n",
    "print(\"\\nVisualisations sauvegardées sous :\")\n",
    "print(\"- data/distributions_numeriques.png\")\n",
    "print(\"- data/boxplots_numeriques.png\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
